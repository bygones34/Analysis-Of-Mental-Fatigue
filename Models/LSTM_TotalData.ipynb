{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ba067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from pywt import wavedec\n",
    "from functools import reduce\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy\n",
    "from scipy.fft import fft, ifft\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold,cross_validate\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, concatenate, Input, Dropout, LSTM, Bidirectional,BatchNormalization,PReLU,ReLU,Reshape\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "import matplotlib.pyplot as plt;\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D,Add\n",
    "from tensorflow.keras.layers import MaxPool1D, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks,layers\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, Input, Dropout, InputLayer, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ea240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Dataset_Combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002a618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>totPwr</th>\n",
       "      <th>status</th>\n",
       "      <th>BVP</th>\n",
       "      <th>ACC_x</th>\n",
       "      <th>ACC_y</th>\n",
       "      <th>ACC_z</th>\n",
       "      <th>EDA</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33448</td>\n",
       "      <td>7054</td>\n",
       "      <td>1692</td>\n",
       "      <td>8833</td>\n",
       "      <td>9796</td>\n",
       "      <td>17692</td>\n",
       "      <td>8025</td>\n",
       "      <td>6926</td>\n",
       "      <td>93466</td>\n",
       "      <td>0</td>\n",
       "      <td>52.20</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.676214</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33448</td>\n",
       "      <td>7054</td>\n",
       "      <td>1692</td>\n",
       "      <td>8833</td>\n",
       "      <td>9796</td>\n",
       "      <td>17692</td>\n",
       "      <td>8025</td>\n",
       "      <td>6926</td>\n",
       "      <td>93466</td>\n",
       "      <td>0</td>\n",
       "      <td>49.83</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.676214</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33448</td>\n",
       "      <td>7054</td>\n",
       "      <td>1692</td>\n",
       "      <td>8833</td>\n",
       "      <td>9796</td>\n",
       "      <td>17692</td>\n",
       "      <td>8025</td>\n",
       "      <td>6926</td>\n",
       "      <td>93466</td>\n",
       "      <td>0</td>\n",
       "      <td>44.65</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.676214</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33448</td>\n",
       "      <td>7054</td>\n",
       "      <td>1692</td>\n",
       "      <td>8833</td>\n",
       "      <td>9796</td>\n",
       "      <td>17692</td>\n",
       "      <td>8025</td>\n",
       "      <td>6926</td>\n",
       "      <td>93466</td>\n",
       "      <td>0</td>\n",
       "      <td>35.26</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.676214</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33448</td>\n",
       "      <td>7054</td>\n",
       "      <td>1692</td>\n",
       "      <td>8833</td>\n",
       "      <td>9796</td>\n",
       "      <td>17692</td>\n",
       "      <td>8025</td>\n",
       "      <td>6926</td>\n",
       "      <td>93466</td>\n",
       "      <td>0</td>\n",
       "      <td>22.66</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.676214</td>\n",
       "      <td>35.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287995</th>\n",
       "      <td>1769201</td>\n",
       "      <td>676309</td>\n",
       "      <td>144288</td>\n",
       "      <td>170323</td>\n",
       "      <td>81213</td>\n",
       "      <td>128252</td>\n",
       "      <td>142854</td>\n",
       "      <td>30079</td>\n",
       "      <td>3142519</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-51</td>\n",
       "      <td>-13</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287996</th>\n",
       "      <td>1769201</td>\n",
       "      <td>676309</td>\n",
       "      <td>144288</td>\n",
       "      <td>170323</td>\n",
       "      <td>81213</td>\n",
       "      <td>128252</td>\n",
       "      <td>142854</td>\n",
       "      <td>30079</td>\n",
       "      <td>3142519</td>\n",
       "      <td>1</td>\n",
       "      <td>6.03</td>\n",
       "      <td>-51</td>\n",
       "      <td>-13</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287997</th>\n",
       "      <td>1769201</td>\n",
       "      <td>676309</td>\n",
       "      <td>144288</td>\n",
       "      <td>170323</td>\n",
       "      <td>81213</td>\n",
       "      <td>128252</td>\n",
       "      <td>142854</td>\n",
       "      <td>30079</td>\n",
       "      <td>3142519</td>\n",
       "      <td>1</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-51</td>\n",
       "      <td>-13</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287998</th>\n",
       "      <td>1769201</td>\n",
       "      <td>676309</td>\n",
       "      <td>144288</td>\n",
       "      <td>170323</td>\n",
       "      <td>81213</td>\n",
       "      <td>128252</td>\n",
       "      <td>142854</td>\n",
       "      <td>30079</td>\n",
       "      <td>3142519</td>\n",
       "      <td>1</td>\n",
       "      <td>6.30</td>\n",
       "      <td>-51</td>\n",
       "      <td>-13</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287999</th>\n",
       "      <td>1769201</td>\n",
       "      <td>676309</td>\n",
       "      <td>144288</td>\n",
       "      <td>170323</td>\n",
       "      <td>81213</td>\n",
       "      <td>128252</td>\n",
       "      <td>142854</td>\n",
       "      <td>30079</td>\n",
       "      <td>3142519</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-51</td>\n",
       "      <td>-13</td>\n",
       "      <td>-37</td>\n",
       "      <td>0.171678</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Delta   Theta   Alpha1   Alpha2   Beta1   Beta2   Gamma1   Gamma2  \\\n",
       "0         33448    7054     1692     8833    9796   17692     8025     6926   \n",
       "1         33448    7054     1692     8833    9796   17692     8025     6926   \n",
       "2         33448    7054     1692     8833    9796   17692     8025     6926   \n",
       "3         33448    7054     1692     8833    9796   17692     8025     6926   \n",
       "4         33448    7054     1692     8833    9796   17692     8025     6926   \n",
       "...         ...     ...      ...      ...     ...     ...      ...      ...   \n",
       "287995  1769201  676309   144288   170323   81213  128252   142854    30079   \n",
       "287996  1769201  676309   144288   170323   81213  128252   142854    30079   \n",
       "287997  1769201  676309   144288   170323   81213  128252   142854    30079   \n",
       "287998  1769201  676309   144288   170323   81213  128252   142854    30079   \n",
       "287999  1769201  676309   144288   170323   81213  128252   142854    30079   \n",
       "\n",
       "         totPwr  status    BVP  ACC_x  ACC_y  ACC_z       EDA   TEMP  \n",
       "0         93466       0  52.20      6      2     65  1.676214  35.55  \n",
       "1         93466       0  49.83      6      2     65  1.676214  35.55  \n",
       "2         93466       0  44.65      6      2     65  1.676214  35.55  \n",
       "3         93466       0  35.26      6      2     65  1.676214  35.55  \n",
       "4         93466       0  22.66      6      2     65  1.676214  35.55  \n",
       "...         ...     ...    ...    ...    ...    ...       ...    ...  \n",
       "287995  3142519       1   5.81    -51    -13    -37  0.171678  34.09  \n",
       "287996  3142519       1   6.03    -51    -13    -37  0.171678  34.09  \n",
       "287997  3142519       1   6.17    -51    -13    -37  0.171678  34.09  \n",
       "287998  3142519       1   6.30    -51    -13    -37  0.171678  34.09  \n",
       "287999  3142519       1   6.48    -51    -13    -37  0.171678  34.09  \n",
       "\n",
       "[288000 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82c2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['ACC_x', 'ACC_y', 'ACC_z']\n",
    "data.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a1cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('status')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f6d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158e5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "X_train = np.array(X_train).reshape(-1,12,1)\n",
    "x_test = np.array(x_test).reshape(-1,12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb93e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(12, 1)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fa9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3825/3825 [==============================] - 78s 19ms/step - loss: 0.5704 - accuracy: 0.6755 - val_loss: 0.4906 - val_accuracy: 0.7401\n",
      "Epoch 2/25\n",
      "3825/3825 [==============================] - 71s 19ms/step - loss: 0.4197 - accuracy: 0.7901 - val_loss: 0.3291 - val_accuracy: 0.8424\n",
      "Epoch 3/25\n",
      "3825/3825 [==============================] - 70s 18ms/step - loss: 0.2509 - accuracy: 0.8885 - val_loss: 0.1402 - val_accuracy: 0.9449\n",
      "Epoch 4/25\n",
      "2533/3825 [==================>...........] - ETA: 21s - loss: 0.1443 - accuracy: 0.9410"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "lstm_model = LSTM_Model()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "lstm_hist = lstm_model.fit(X_train, y_train,\n",
    "                           validation_data=(x_test, y_test),\n",
    "                           epochs=25,\n",
    "                           steps_per_epoch=X_train.shape[0]//batch_size,\n",
    "                          callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
